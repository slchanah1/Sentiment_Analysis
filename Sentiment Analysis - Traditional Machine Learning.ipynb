{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/ivan/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import keras\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from py_translator import Translator\n",
    "\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "\n",
    "from sklearn import random_projection\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten, Reshape\n",
    "from keras.layers import Conv1D, Conv2D, Convolution2D, MaxPool2D, MaxPooling2D, Flatten, Reshape, BatchNormalization, Concatenate\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "# from tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.pooling import GlobalAveragePooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping\n",
    "\n",
    "stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train = pd.read_csv(\"./data/train.csv\")\n",
    "Valid = pd.read_csv(\"./data/valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsvFUqrhytVmKXCW7bKNhA</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-10 01:24:07</td>\n",
       "      <td>0</td>\n",
       "      <td>58nqw-MdO6EDACPaKDM59Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>As a student, by back and neck are under const...</td>\n",
       "      <td>0</td>\n",
       "      <td>1NImHsg1kc76n_cQyTm0bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6YrO-hJNof4wsx4f0YQ8yg</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-22 17:06:23</td>\n",
       "      <td>0</td>\n",
       "      <td>eVeQtMGaB5tdCH0hKJwxKw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stayed here for a football game at University ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Oi0G3jFm2jtG2W02dZTdEQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LtyoPfxpvcF_9e9wMoUi0w</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-25 09:55:57</td>\n",
       "      <td>0</td>\n",
       "      <td>AHMHUbq0eAUOuOPFoeO5iw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very good salads, generous portions. I either ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4jbz7cOVuV_Q7v2b3pNrLw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QzvLnOqwH6BIY_jCOvzuQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-06 04:18:48</td>\n",
       "      <td>0</td>\n",
       "      <td>8RDvwneSMsbpmi5UgGq60A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The experience I had with this company growing...</td>\n",
       "      <td>0</td>\n",
       "      <td>gJgPs0QXE587T9SIR6NCdQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tPaweigPsXacvQT8daYT4g</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-22 15:38:59</td>\n",
       "      <td>0</td>\n",
       "      <td>IboCoxoL0IFtJnsGPHCugg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Easiest furniture purchase, with a great price...</td>\n",
       "      <td>0</td>\n",
       "      <td>zp8XLBJmgw55ZTlp5raK7Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                 date  funny  \\\n",
       "0  dsvFUqrhytVmKXCW7bKNhA     0  2013-03-10 01:24:07      0   \n",
       "1  6YrO-hJNof4wsx4f0YQ8yg     0  2014-12-22 17:06:23      0   \n",
       "2  LtyoPfxpvcF_9e9wMoUi0w     0  2016-04-25 09:55:57      0   \n",
       "3  QzvLnOqwH6BIY_jCOvzuQQ     0  2017-04-06 04:18:48      0   \n",
       "4  tPaweigPsXacvQT8daYT4g     0  2017-03-22 15:38:59      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  58nqw-MdO6EDACPaKDM59Q    5.0   \n",
       "1  eVeQtMGaB5tdCH0hKJwxKw    3.0   \n",
       "2  AHMHUbq0eAUOuOPFoeO5iw    4.0   \n",
       "3  8RDvwneSMsbpmi5UgGq60A    1.0   \n",
       "4  IboCoxoL0IFtJnsGPHCugg    5.0   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  As a student, by back and neck are under const...       0   \n",
       "1  Stayed here for a football game at University ...       0   \n",
       "2  Very good salads, generous portions. I either ...       1   \n",
       "3  The experience I had with this company growing...       0   \n",
       "4  Easiest furniture purchase, with a great price...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  1NImHsg1kc76n_cQyTm0bg  \n",
       "1  Oi0G3jFm2jtG2W02dZTdEQ  \n",
       "2  4jbz7cOVuV_Q7v2b3pNrLw  \n",
       "3  gJgPs0QXE587T9SIR6NCdQ  \n",
       "4  zp8XLBJmgw55ZTlp5raK7Q  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train['text'] = Train['text'].apply(lambda row:' '.join(list(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dsvFUqrhytVmKXCW7bKNhA</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-10 01:24:07</td>\n",
       "      <td>0</td>\n",
       "      <td>58nqw-MdO6EDACPaKDM59Q</td>\n",
       "      <td>5.0</td>\n",
       "      <td>As a student, by back and neck are under const...</td>\n",
       "      <td>0</td>\n",
       "      <td>1NImHsg1kc76n_cQyTm0bg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6YrO-hJNof4wsx4f0YQ8yg</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-12-22 17:06:23</td>\n",
       "      <td>0</td>\n",
       "      <td>eVeQtMGaB5tdCH0hKJwxKw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Stayed here for a football game at University ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Oi0G3jFm2jtG2W02dZTdEQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LtyoPfxpvcF_9e9wMoUi0w</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-25 09:55:57</td>\n",
       "      <td>0</td>\n",
       "      <td>AHMHUbq0eAUOuOPFoeO5iw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Very good salads, generous portions. I either ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4jbz7cOVuV_Q7v2b3pNrLw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QzvLnOqwH6BIY_jCOvzuQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-04-06 04:18:48</td>\n",
       "      <td>0</td>\n",
       "      <td>8RDvwneSMsbpmi5UgGq60A</td>\n",
       "      <td>1.0</td>\n",
       "      <td>The experience I had with this company growing...</td>\n",
       "      <td>0</td>\n",
       "      <td>gJgPs0QXE587T9SIR6NCdQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tPaweigPsXacvQT8daYT4g</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-03-22 15:38:59</td>\n",
       "      <td>0</td>\n",
       "      <td>IboCoxoL0IFtJnsGPHCugg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Easiest furniture purchase, with a great price...</td>\n",
       "      <td>0</td>\n",
       "      <td>zp8XLBJmgw55ZTlp5raK7Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool                 date  funny  \\\n",
       "0  dsvFUqrhytVmKXCW7bKNhA     0  2013-03-10 01:24:07      0   \n",
       "1  6YrO-hJNof4wsx4f0YQ8yg     0  2014-12-22 17:06:23      0   \n",
       "2  LtyoPfxpvcF_9e9wMoUi0w     0  2016-04-25 09:55:57      0   \n",
       "3  QzvLnOqwH6BIY_jCOvzuQQ     0  2017-04-06 04:18:48      0   \n",
       "4  tPaweigPsXacvQT8daYT4g     0  2017-03-22 15:38:59      0   \n",
       "\n",
       "                review_id  stars  \\\n",
       "0  58nqw-MdO6EDACPaKDM59Q    5.0   \n",
       "1  eVeQtMGaB5tdCH0hKJwxKw    3.0   \n",
       "2  AHMHUbq0eAUOuOPFoeO5iw    4.0   \n",
       "3  8RDvwneSMsbpmi5UgGq60A    1.0   \n",
       "4  IboCoxoL0IFtJnsGPHCugg    5.0   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  As a student, by back and neck are under const...       0   \n",
       "1  Stayed here for a football game at University ...       0   \n",
       "2  Very good salads, generous portions. I either ...       1   \n",
       "3  The experience I had with this company growing...       0   \n",
       "4  Easiest furniture purchase, with a great price...       0   \n",
       "\n",
       "                  user_id  \n",
       "0  1NImHsg1kc76n_cQyTm0bg  \n",
       "1  Oi0G3jFm2jtG2W02dZTdEQ  \n",
       "2  4jbz7cOVuV_Q7v2b3pNrLw  \n",
       "3  gJgPs0QXE587T9SIR6NCdQ  \n",
       "4  zp8XLBJmgw55ZTlp5raK7Q  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([Train, Valid])\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Rare words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "boozy.         1\n",
       "laterrrr       1\n",
       "CONs--Small    1\n",
       "Cherries.      1\n",
       "biers          1\n",
       "three...       1\n",
       "1500.00.       1\n",
       "Valley.)       1\n",
       "features).     1\n",
       "gruel.         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(df['text']).split()).value_counts()[-10:]\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq = list(freq.index)\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['text'] = [word_tokenize(entry) for entry in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag_map = defaultdict(lambda : wordnet.NOUN)\n",
    "tag_map['J'] = wordnet.ADJ\n",
    "tag_map['V'] = wordnet.VERB\n",
    "tag_map['R'] = wordnet.ADV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization(df):\n",
    "    for index,entry in enumerate(df['text']):\n",
    "        # Declaring Empty List to store the words that follow the rules for this step\n",
    "        Final_words = []\n",
    "        # Initializing WordNetLemmatizer()\n",
    "        word_Lemmatized = WordNetLemmatizer()\n",
    "        # pos_tag function below will provide the 'tag' i.e if the word is Noun(N) or Verb(V) or something else.\n",
    "        for word, tag in pos_tag(entry):\n",
    "            # Below condition is to check for Stop words and consider only alphabets\n",
    "            if word not in stopwords.words('english') and word.isalpha():\n",
    "                word_Final = word_Lemmatized.lemmatize(word,tag_map[tag[0]])\n",
    "                Final_words.append(word_Final)\n",
    "        # The final processed set of words for each iteration will be stored in 'text_final'\n",
    "        df.loc[index,'text_final'] = str(Final_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmatization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"pre_processed_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Preview Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/pre_processed_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "      <th>text_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['student', 'back', 'neck', 'constant', 'strai...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>48</td>\n",
       "      <td>295</td>\n",
       "      <td>5.166667</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['student', 'back', 'neck', 'constant', 'strai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['stayed', 'football', 'game', 'university', '...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37</td>\n",
       "      <td>218</td>\n",
       "      <td>4.918919</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['stay', 'football', 'game', 'university', 'ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['good', 'salads', 'generous', 'portions', 'ei...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19</td>\n",
       "      <td>106</td>\n",
       "      <td>4.631579</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>['good', 'salad', 'generous', 'portion', 'eith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['experience', 'company', 'growing', 'awesome'...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>134</td>\n",
       "      <td>716</td>\n",
       "      <td>4.343284</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>['experience', 'company', 'grow', 'awesome', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['easiest', 'furniture', 'purchase', 'great', ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19</td>\n",
       "      <td>122</td>\n",
       "      <td>5.473684</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>['easy', 'furniture', 'purchase', 'great', 'pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars  word_count  \\\n",
       "0  ['student', 'back', 'neck', 'constant', 'strai...    5.0          48   \n",
       "1  ['stayed', 'football', 'game', 'university', '...    3.0          37   \n",
       "2  ['good', 'salads', 'generous', 'portions', 'ei...    4.0          19   \n",
       "3  ['experience', 'company', 'growing', 'awesome'...    1.0         134   \n",
       "4  ['easiest', 'furniture', 'purchase', 'great', ...    5.0          19   \n",
       "\n",
       "   char_count  avg_word  stopwords  hastags  numerics  upper  \\\n",
       "0         295  5.166667         14        0         0      2   \n",
       "1         218  4.918919         13        0         0      0   \n",
       "2         106  4.631579          4        0         0      2   \n",
       "3         716  4.343284         55        0         2      7   \n",
       "4         122  5.473684          6        0         0      0   \n",
       "\n",
       "                                          text_final  \n",
       "0  ['student', 'back', 'neck', 'constant', 'strai...  \n",
       "1  ['stay', 'football', 'game', 'university', 'ph...  \n",
       "2  ['good', 'salad', 'generous', 'portion', 'eith...  \n",
       "3  ['experience', 'company', 'grow', 'awesome', '...  \n",
       "4  ['easy', 'furniture', 'purchase', 'great', 'pr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features=10000, lowercase=True,\n",
    "                        stop_words='english', ngram_range=(1, 2))\n",
    "\n",
    "vect_train = tfidf.fit_transform(df['text_final'].iloc[:100000])\n",
    "vect_test = tfidf.transform(df['text_final'].iloc[100000:])\n",
    "vocab = tfidf.vocabulary_\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 10000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able come</th>\n",
       "      <th>able eat</th>\n",
       "      <th>able enjoy</th>\n",
       "      <th>able help</th>\n",
       "      <th>able make</th>\n",
       "      <th>able order</th>\n",
       "      <th>...</th>\n",
       "      <th>zen</th>\n",
       "      <th>zero</th>\n",
       "      <th>zero star</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>ça</th>\n",
       "      <th>était</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 10000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aaa  aaron  ability  able  able come  able eat  able enjoy  able help  \\\n",
       "0  0.0    0.0      0.0   0.0        0.0       0.0         0.0        0.0   \n",
       "1  0.0    0.0      0.0   0.0        0.0       0.0         0.0        0.0   \n",
       "2  0.0    0.0      0.0   0.0        0.0       0.0         0.0        0.0   \n",
       "3  0.0    0.0      0.0   0.0        0.0       0.0         0.0        0.0   \n",
       "4  0.0    0.0      0.0   0.0        0.0       0.0         0.0        0.0   \n",
       "\n",
       "   able make  able order  ...    zen  zero  zero star  zip  zombie  zone  zoo  \\\n",
       "0        0.0         0.0  ...    0.0   0.0        0.0  0.0     0.0   0.0  0.0   \n",
       "1        0.0         0.0  ...    0.0   0.0        0.0  0.0     0.0   0.0  0.0   \n",
       "2        0.0         0.0  ...    0.0   0.0        0.0  0.0     0.0   0.0  0.0   \n",
       "3        0.0         0.0  ...    0.0   0.0        0.0  0.0     0.0   0.0  0.0   \n",
       "4        0.0         0.0  ...    0.0   0.0        0.0  0.0     0.0   0.0  0.0   \n",
       "\n",
       "   zucchini   ça  était  \n",
       "0       0.0  0.0    0.0  \n",
       "1       0.0  0.0    0.0  \n",
       "2       0.0  0.0    0.0  \n",
       "3       0.0  0.0    0.0  \n",
       "4       0.0  0.0    0.0  \n",
       "\n",
       "[5 rows x 10000 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the Model as a pandas DataFrame\n",
    "feature_names = tfidf.get_feature_names()\n",
    "vectdf = pd.DataFrame(vect_train.toarray(), columns = feature_names)\n",
    "vectdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Adding and Normalising features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train['useful_nom'] = (Train['useful']-min(Train['useful']))/(max(Train['useful'])-min(Train['useful']))\n",
    "Train['funny_nom'] = (Train['funny']-min(Train['funny']))/(max(Train['funny'])-min(Train['funny']))\n",
    "Train['cool_nom'] = (Train['cool']-min(Train['cool']))/(max(Train['cool'])-min(Train['cool']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Valid['useful_nom'] = (Valid['useful']-min(Valid['useful']))/(max(Valid['useful'])-min(Valid['useful']))\n",
    "Valid['funny_nom'] = (Valid['funny']-min(Valid['funny']))/(max(Valid['funny'])-min(Valid['funny']))\n",
    "Valid['cool_nom'] = (Valid['cool']-min(Valid['cool']))/(max(Valid['cool'])-min(Valid['cool']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, hstack\n",
    "def add_feature(X, feature_to_add):\n",
    "    \"\"\"\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    \"\"\"\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_train = Train['useful_nom']\n",
    "useful_test = Valid['useful_nom']\n",
    "funny_train = Train['funny_nom']\n",
    "funny_test = Valid['funny_nom']\n",
    "cool_train = Train['cool_nom']\n",
    "cool_test = Valid['cool_nom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect_train2 = add_feature(vect_train, useful_train)\n",
    "vect_train2 = add_feature(vect_train2, funny_train)\n",
    "vect_train2 = add_feature(vect_train2, cool_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect_test2 = add_feature(vect_test, useful_test)\n",
    "vect_test2 = add_feature(vect_test2, funny_test)\n",
    "vect_test2 = add_feature(vect_test2, cool_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10003)\n",
      "(100000, 10003)\n"
     ]
    }
   ],
   "source": [
    "print(vect_test2.shape)\n",
    "print(vect_train2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Logitisic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_y = df['stars'].iloc[:100000]\n",
    "Test_y = df['stars'].iloc[100000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_predict_model(classifier, \n",
    "                        train_features, train_labels, \n",
    "                        test_features, test_labels):\n",
    "    # build model    \n",
    "    classifier.fit(train_features, train_labels)\n",
    "    # predict using model\n",
    "    predictions = classifier.predict(test_features) \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 65.11\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1)\n",
    "lr_bow_predictions = train_predict_model(classifier=lr, \n",
    "                                             train_features=vect_train2, train_labels=Train_y,\n",
    "                                             test_features=vect_test2, test_labels=Test_y)\n",
    "\n",
    "print('Test Accuracy:', accuracy_score(lr_bow_predictions, Test_y)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_x = vect_train2\n",
    "Test_x = vect_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifier - Algorithm - SVM\n",
    "# fit the training dataset on the classifier\n",
    "SVM = svm.SVC(C=1.0, kernel='linear', degree=5, gamma='auto')\n",
    "k_fold_scores = cross_validation.cross_val_score(SVM, Train_x, Train_y, cv=5)\n",
    "\n",
    "SVM.fit(Train_x,Train_y)\n",
    "# predict the labels on validation dataset\n",
    "predictions_SVM_train = SVM.predict(Train_x)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM_train, Train_y)*100)\n",
    "\n",
    "predictions_SVM_test = SVM.predict(Test_x)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM_test, Test_y)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib \n",
    "\n",
    "#joblib.dump(SVM, 'SVM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_loaded Accuracy Score ->  41.72\n"
     ]
    }
   ],
   "source": [
    "SVM_loaded = joblib.load('SVM.pkl')\n",
    "\n",
    "\n",
    "predictions_SVM_loaded_test = SVM_loaded.predict(Test_x)\n",
    "# Use accuracy_score function to get the accuracy\n",
    "print(\"SVM_loaded Accuracy Score -> \",accuracy_score(predictions_SVM_loaded_test, Test_y)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 GaussianNB and MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Accuracy (Train): 0.55613\n",
      "GaussianNB Accuracy (Test): 0.4787\n",
      "MultinomialNB Accuracy (Train): 0.55613\n",
      "MultinomialNB Accuracy (Test): 0.6122\n"
     ]
    }
   ],
   "source": [
    "classifierGNB = GaussianNB()\n",
    "classifierGNB.fit(vect_train2.toarray(), Train_y)\n",
    "GNB_y_train_pred = classifierGNB.predict(vect_train2.toarray())\n",
    "GNB_y_test_pred = classifierGNB.predict(vect_test2.toarray())\n",
    "\n",
    "print(\"GaussianNB Accuracy (Train):\",accuracy_score(Train_y, GNB_y_train_pred))\n",
    "print(\"GaussianNB Accuracy (Test):\",accuracy_score(Test_y, GNB_y_test_pred))\n",
    "\n",
    "# Model Generation Using Multinomial Naive Bayes\n",
    "clf = MultinomialNB().fit(vect_train2, Train_y)\n",
    "MGNB_y_train_pred = classifierGNB.predict(vect_train2.toarray())\n",
    "MGNB_y_test_pred = clf.predict(vect_test2.toarray())\n",
    "\n",
    "print(\"MultinomialNB Accuracy (Train):\",accuracy_score(Train_y, MGNB_y_train_pred))\n",
    "print(\"MultinomialNB Accuracy (Test):\",accuracy_score(Test_y, MGNB_y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
